{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "data = pandas.read_csv(\"data/titanic.csv\")\n",
    "#check if data loaded by grabbing first 5\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Prediction\n",
    "\n",
    "The role of machine learning is to discover patterns and relationship in data and to put those use. The end goal is pretty simple though the methods may range from simple to extremely complicated, the goal however is to take the known and predict what we don't know. \n",
    "\n",
    "### Finding relationships between input and target (label) data\n",
    "\n",
    "Trying to predict MPG for vehicles. The dataset could have model year, vehicle weight, horsepower, number of cylinders so on and the vehicles MPG rating. \n",
    "\n",
    "Input features are typically referred to using the symbol X, with subscripts differenting inputs when multiple input features exist. For example X_1 refers to manufactuer region, X_2 to model year and so on. \n",
    "\n",
    "Target variable is typically referred as Y. So a simple formula could be\n",
    "\n",
    "Y = f(X) + Error\n",
    "\n",
    "f: is the unknown function that relates the input variables to the target, Y. It is commonly referred to as the signal. \n",
    "\n",
    "E:(error) is called noise.\n",
    "\n",
    "##### \"The challenge of machine learning is to use data to determine what the true signal is, while ignoring noise\"\n",
    "\n",
    "If you knew f() in the auto mobile challenge then you'd be able to know the MPG rating of any car. But you could have numerous sources of noise, E, including:\n",
    "\n",
    "1. imperfect measurement of each vehicle's MPG rating cased by small inaccuracies in the measuring devices --measurement noise\n",
    "2. Variations in manufacturing process, causing each care in the fleet to have slightly different MPG measurements --- manufacturing process noise\n",
    "3. Noise in the measurement of the input features, such as weight and horsepower\n",
    "4. Lack of access to the braoder set of features that would exactly determine MPG\n",
    "\n",
    "Assuming a good estimate of f. Machine learning has 2 goals predictions and inference. \n",
    "\n",
    "#### Prediction\n",
    "\n",
    "Giving a healthymodel you can generate predictions of the target (Y) given new information (X_new). Giving you new data as needed. \n",
    "\n",
    "Examples of ML prediction cases:\n",
    "deciphering handwritten digits or voice recordings\n",
    "predicting stock market\n",
    "forecasting\n",
    "predicting which users are most likely to click, convert or buy\n",
    "predicting which users will need product support and which are liekly to unsubscribe\n",
    "determining which transactions are fraudulent\n",
    "making recommendations\n",
    "\n",
    "#### Inference\n",
    "\n",
    "machine learning models and better understand the relationships between theinput features and the output target. Such as:\n",
    "\n",
    "which input features are most strongly related to the target variable?\n",
    "Are those relationships positive or negative?\n",
    "Is f a simple relationship, or is it a function that's more nuanced and nonlinear?\n",
    "\n",
    "## Models\n",
    "\n",
    "#### Parametric vs nonparametric\n",
    "assume that f takes a specific functional form, whereas nonparametric models don't make such strict assumptions. Parametric approaches tend to be simple and interpretable, but less accurate. \n",
    "\n",
    "Nonparametric approaches are usually les interpretable but more accurate across a broad range of problems. \n",
    "\n",
    "### Parametric Methods\n",
    "\n",
    "linear regression is a parametric models. It assumes f is a linear combination of the numerical values of the inputs. \n",
    "\n",
    "f(X) = B_0 + X_1 x B_1 + X_2 x B_2\n",
    "\n",
    "other commonly used parametric models include:\n",
    "\n",
    "logistic regression\n",
    "polynomial regression\n",
    "linear discriminant analysis\n",
    "quadratic discriminant analysis\n",
    "(parametric) mixture models\n",
    "naive bayes\n",
    "\n",
    "#### drawbacks\n",
    "\n",
    "the biggest drawback is the strong assumption about the true form of the function\n",
    "\n",
    "### Nonparametric methods\n",
    "\n",
    "f doesn't take a simple fixed function. The form and complexity of f adapts to complexity of the data. For example a classification tree.\n",
    "\n",
    "Other examples:\n",
    "k-nearest neighbors\n",
    "splines\n",
    "basis expansion methods\n",
    "kernal smoothing\n",
    "generalized additive models\n",
    "neural nets\n",
    "bagging\n",
    "boosting\n",
    "random forests\n",
    "support vector machines\n",
    "\n",
    "\n",
    "### supervised vs unsupervised\n",
    "\n",
    "supervised problems is where you have access to the target variable for set of training data. Unsupervised are ones in which there's no identified target variable.\n",
    "\n",
    "unsupervised have 2 main classes:\n",
    "\n",
    "#### clustering\n",
    "\n",
    "use the inpute features to discover natural groupings (k-means so on)\n",
    "\n",
    "#### dimensionality reduction\n",
    "transform the input features into a small number of coordinates that caputre most of the variability of the data (principle component analysis (PCA), multidimensional scaling, manifold learning\n",
    "\n",
    "### Classifications\n",
    "\n",
    "this is about putting things into buckets so to speak\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example code\n",
    "from sklearn.linear_model import LogisticRegression as Model\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 80/20 train test split\n",
    "data_train = data[:int(0.8*len(data))]\n",
    "data_test = data[int(0.8*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(data):\n",
    "    categories = unique(data)\n",
    "    features = {}\n",
    "    for cat in categories:\n",
    "        binary = (data == cat)\n",
    "        features[\"%s=%s\" % (data.name, cat)] = binary.astype(\"int\")\n",
    "    return pandas.DataFrame(features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\"Takes a dataframe of raw data and returns ML model features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initially, we build a model only on the available numerical values\n",
    "    features = data.drop([\"PassengerId\", \"Survived\", \"Fare\", \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"], axis=1)\n",
    "    \n",
    "    # Setting missing age values to -1\n",
    "    features[\"Age\"] = data[\"Age\"].fillna(-1)\n",
    "    \n",
    "    # Adding the sqrt of the fare feature\n",
    "    features[\"sqrt_Fare\"] = sqrt(data[\"Fare\"])\n",
    "    \n",
    "    # Adding gender categorical value\n",
    "    features = features.join( cat_to_num(data['Sex']) )\n",
    "    \n",
    "\n",
    "    # Adding Embarked categorical value\n",
    "    \n",
    "    #features = features.join( cat_to_num(data['Embarked']) )\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building logistical regression classifier via scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>sqrt_Fare</th>\n",
       "      <th>Sex=female</th>\n",
       "      <th>Sex=male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.692582</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.442944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.815138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.286975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.837252</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch  sqrt_Fare  Sex=female  Sex=male\n",
       "0       3  22.0      1      0   2.692582           0         1\n",
       "1       1  38.0      1      0   8.442944           1         0\n",
       "2       3  26.0      0      0   2.815138           1         0\n",
       "3       1  35.0      1      0   7.286975           1         0\n",
       "4       3  35.0      0      0   2.837252           0         1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the features\n",
    "features = prepare_data(data_train)\n",
    "#see if it worked with the first 5 entries\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(features, target):\n",
    "    print(features)\n",
    "    print(target)\n",
    "    model = Model()\n",
    "    model.fit(features, target)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, new_features):\n",
    "    preds = model.predict(new_features)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.fit(features, data_train[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prepare_data(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82122905027932958"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the accuracy\n",
    "model.score(prepare_data(data_test), data_test[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Is the simplest ML algo for classification problems. To understand think of a problem as only having to features and a dataset divided into 2 classes. Such as the titanic features of Age and sqft(Fare). The target(label) data of survived or died. \n",
    "\n",
    "The Algo consists of the following steps:\n",
    "1. You can start the search by picking the parameter values at random, hence lacing a random line in an x,y chart for visualization\n",
    "2. Measure how well this line separates the 2 classes. In logistic regression, you use the statistical deviances for the 'goodness-of-fit' measurement. \n",
    "3. Guess new values of the parameters and measure the separation power.\n",
    "4. Repeat until there are no better guesses. This is an optimization procedure that can be done with a range of optimization algorithms. Gradient descent is a popular choice for a simple optimization algo.\n",
    "\n",
    "This approach can be extended to more dimensions, so you're not limited to 2 features. \n",
    "\n",
    "Some aspects of logistic regression:\n",
    "\n",
    "1. The algo is simple to understand both from a human and computationally speaking\n",
    "2. The performance will degrade if the decision boundary that separates teh classes needs to be highly nonlinear\n",
    "3. Logistic regression algorithms can sometimes overfit the data, and you often need to use a technique called regularization that limits this danger\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building SVM (support vector machines) nonlinear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(features, data_train[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86033519553072624"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(prepare_data(data_test), data_test[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "It has a similiar concept as logistic regression. Find the line (or equivalent in higher dimensions) that separates the classes optimally. Instead of measuring the distance to all points, SVMs try to find the largetst margin between only the points on either side of the decision line. The idea is that there's no reason to worry about points that are well within the boundary, only ones that are close.\n",
    "\n",
    "## Multiple classes\n",
    "\n",
    "Handwritten digit recognition is the 'hello world' for multiple class machine learning problems. MNIST database of handwritten digits is the most popularly known db for this. The images are 28 x 28 pixels. \n",
    "\n",
    "To solve this problem you square the pixel dimensions to make 784. Each pixel is then a feature. \n",
    "\n",
    "Then find a non-linear algo that supports multiclass problems. k-nearest neighbor is such one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pandas.read_csv(\"data/mnist_small.csv\")\n",
    "mnist_train = mnist[:int(0.8*len(mnist))]\n",
    "mnist_test = mnist[int(0.8*len(mnist)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  1. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0.3,  0. ,  0. ,  0. ,  0. ,  0. ,  0.6,  0. ,  0.1,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.1,  0. ,  0. ,  0. ,  0.5,  0. ,  0.4],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0.7,  0. ,  0. ,  0. ,  0. ,  0.3]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(mnist_train.drop(\"label\", axis=1), mnist_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Digit 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digit 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digit 3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digit 4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digit 5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1    2    3    4    5    6    7    8    9\n",
       "Digit 1  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "Digit 2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "Digit 3  0.3  0.0  0.0  0.0  0.0  0.0  0.6  0.0  0.1  0.0\n",
       "Digit 4  0.0  0.0  0.0  0.1  0.0  0.0  0.0  0.5  0.0  0.4\n",
       "Digit 5  0.0  0.0  0.0  0.0  0.7  0.0  0.0  0.0  0.0  0.3"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = knn.predict_proba(mnist_test.drop('label', axis=1))\n",
    "pandas.DataFrame(preds[:5], index=[\"Digit %d\"%(i+1) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81999999999999995"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(mnist_test.drop('label', axis=1), mnist_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors\n",
    "\n",
    "The k-nearest neighbors algo is a nonlinear ML method. It's used when model training should be quick but predictions are typically slower. \n",
    "\n",
    "The basic idea is you can classify new data record by comparing it with similiar records from the training set. If a dataset record consists of a set of numbers, n_i, you can find the distance between recrods via the usual distance formula\n",
    "\n",
    "d = sqrt(n_1^2 + n_2^2...)\n",
    "\n",
    "If you're using 1-nearest neighbor. You would find the closest known recrod and assign that class to the new record. Normally you'd use 3,5 or 9 neighbors and pick the class that's most common among neighbors using odd numbers to avoid ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>modelyear</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  modelyear  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0         70   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5         70   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0         70   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0         70   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5         70   \n",
       "\n",
       "   origin  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pandas.read_csv('data/auto-mpg.csv')\n",
    "\n",
    "auto[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert origin to categorical variable\n",
    "auto = auto.join(cat_to_num(auto['origin']))\n",
    "auto = auto.drop('origin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>modelyear</th>\n",
       "      <th>origin=1</th>\n",
       "      <th>origin=2</th>\n",
       "      <th>origin=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  modelyear  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0         70   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5         70   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0         70   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0         70   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5         70   \n",
       "\n",
       "   origin=1  origin=2  origin=3  \n",
       "0         1         0         0  \n",
       "1         1         0         0  \n",
       "2         1         0         0  \n",
       "3         1         0         0  \n",
       "4         1         0         0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split training data\n",
    "auto_train = auto[:int(0.8*len(auto))]\n",
    "auto_test = auto[int(0.8*len(auto)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(auto_train.drop('mpg', axis=1), auto_train['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_mpg = reg.predict(auto_test.drop('mpg', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21492576400>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpYIB3Qzs0T8f7L7UN0dS3wdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214924dd2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(auto_test.mpg, pred_mpg, 'o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "The simplest and most widely used algo for building regression models. The main strengths are linear scalability and a high level of interpretability.\n",
    "\n",
    "This algo plots the dataset records as points, with the target variable on the y-axis and fits a straight line or plane in the case of two or more features to these points.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "This is a highly accurate nonlinear algo that is widely used in real-world classification and regression problems. \n",
    "\n",
    "The basis is a decision tree. It allows sorting the most important decisions and puts it to the top of the tree and then introduces less important varaibles gradually as 'questions' are answered.\n",
    "\n",
    "#### Drabacks\n",
    "\n",
    "Early decisions have major impact on the resulting answer. New data doesn't always follow exactly the same distro as the training set. So generalizing may be a problem.\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "Immunity to unimportant features, noisy datasets in terms ofmissing data and mislabled records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
