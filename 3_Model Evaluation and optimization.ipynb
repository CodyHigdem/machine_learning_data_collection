{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and optimization\n",
    "\n",
    "In the steps of machine learning you:\n",
    "1. take data\n",
    "2. build a model\n",
    "3. evaluate a model\n",
    "4. optimize it\n",
    "5. rebuild if needed\n",
    "Then lookst at new data and the prediction\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "Usually the main goal is to make accurate predictions. One measure of performance on a model is how well tha t5model will perform on new data. \n",
    "\n",
    "#### Overfitting & model optimism\n",
    "\n",
    "#### Cross-validation\n",
    "\n",
    "holdout method because a random subset of the training data is held out from the training process. So you use a training subset to fit the model and only the testing subset to evaluate the accuracy of the model. \n",
    "\n",
    "Leave out 20 - 40$ of the data as the testing subset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make up some data\n",
    "features = rand(100,5)\n",
    "target = rand(100) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#holdout method\n",
    "N = features.shape[0]\n",
    "print(N)\n",
    "N_train = int(floor(0.7 * N))\n",
    "print(N_train)\n",
    "#do this step if you want to randomize the index\n",
    "idx = random.permutation(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split to training/test\n",
    "idx_train = idx[:N_train]\n",
    "idx_test = idx[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split into subsets\n",
    "features_train = features[idx_train,:]\n",
    "target_train = target[idx_train]\n",
    "features_test = features[idx_test,:]\n",
    "target_test = target[idx_test]\n",
    "\n",
    "#Then do rest of the machine learning stuff i.e.\n",
    "#model = train(features_train, target_train)\n",
    "#preds_test = predict(model, features_test)\n",
    "#accuracy = evaluate_accuracy(preds_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold cross-validation\n",
    "\n",
    "just like holdout you have to split subsets of training data during the learning process. The difference is k-old begins by randomly splitting the data into k disjoint subsets, called folds. Typically (5, 10, 20)\n",
    "\n",
    "The predictions are aggregated after all the cycles have been completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#examle\n",
    "N = features.shape[0]\n",
    "K = 10 #number of folds you want\n",
    "\n",
    "preds_kfold = np.empty(N)\n",
    "folds = np.random.randint(0, K, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  8 11 22 24 54 63 69 71 82]\n",
      "[ 7 19 29 39 44 47 49 51 57 76]\n",
      "[21 25 42 45 56 65 85]\n",
      "[15 27 31 40 41 53 61 67]\n",
      "[ 2 10 17 38 43 70 84 87 98]\n",
      "[33 58 59 62 64 66 74 83 88 89 91 94 95]\n",
      "[ 4 12 16 20 52 68 73 77 80]\n",
      "[ 3 14 32 34 60 72 81 86 90 99]\n",
      "[ 1  5  6 26 30 46 48 50 55 75]\n",
      "[ 9 13 18 23 28 35 36 37 78 79 92 93 96 97]\n"
     ]
    }
   ],
   "source": [
    "for idx in np.arange(K):\n",
    "    #each fold break the data into training and testin gsubsets\n",
    "    features_train = features[folds != idx, :]\n",
    "    target_train = target[folds != idx]\n",
    "    features_test = features[folds == idx, :]\n",
    "    \n",
    "    print(nonzero(folds == idx)[0])\n",
    "    \n",
    "    #build and predict\n",
    "    #model = train(features_train, target_train)\n",
    "    #preds_kfold[folds == idx] = predict(model, features_test)\n",
    "#accuracy = evaluate_acc(preds_kfold, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Gives you a way to estimate how accurately your ML models will predict when deployed in the wild. Things to look out for\n",
    "\n",
    "1. CV methods assume that the training data forms a representative smaple from the population of interest. If you plan to deploy te modle to predict on new data, that data should be well represented by the training data. if not, the cross-validation error estimates may be overly optimistic for the error rates on future data. Solution: Ensure that any potential biases in the training data are addressed and minimized. \n",
    "2. Some datasets use features that are temporal-- for instance, using last month's revenue to forecast this month's revenue. If this is the case with your data, you must ensure that features that are available in the future can never be used to predict the past. Solution: you can structure your cross-validation holdout set or k-folds so that all the training set data is collected previous to the testing set. \n",
    "The larger the number of folds used in k-fold the better the error estimates will be, but the longer your program will take to run. Solution: use at least 10 folds (or more) when you can. For modles that train and predict quickly, you can use leave-one-out CV (k = number of data instances)\n",
    "\n",
    "#### Confusion-Matrix\n",
    "\n",
    "When checking accuracy of aclassifier it may be a good estimate of accuracy by getting a percentage of items classified properly BY class. A confusion matrix could help visualize this. \n",
    "\n",
    "i.e. \n",
    "\n",
    "2/3 correct as 1\n",
    "1 of 1 correct as 0\n",
    "1 of 3 false as 0\n",
    "0 of 1 false as 1\n",
    "\n",
    "This then shows the class wide accuracy between ture positive rate, false positive rate, false negative rate and true negative rate. \n",
    "\n",
    "#### ROC curves\n",
    "receiver operating characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#roc curve\n",
    "def roc_curve(true_labels, predicted_probs, n_points=100, pos_class=1):\n",
    "    thr = np.linspace(0,1, n_points)\n",
    "    tpr = zeros(n_points)\n",
    "    fpr = zeros(n_points)\n",
    "    \n",
    "    pos = true_labels == pos_class\n",
    "    neg = logical_not(pos)\n",
    "    n_pos = count_nonzero(pos)\n",
    "    n_neg = count_nonzero(neg)\n",
    "    \n",
    "    for i, t in enumerate(thr):\n",
    "        tpr[i] = count_nonzero(logical_and(predicted_probs >= t, pos)) / n_pos\n",
    "        fpr[i] = count_nonzero(logical_and(predicted_probs >= t, neg)) / n_neg\n",
    "    return fpr, tpr, thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1944d2505c0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkEKdxGRCFK4i4hE0P8HBh74y68zVOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1944d0a7c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#rando generated predictions should give us a roc curve\n",
    "preds = rand(len(target))\n",
    "fpr, tpr, thr = roc_curve(target, preds, pos_class=True)\n",
    "plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the area under the roc curve\n",
    "def auc(true_labels, predicted_labels, pos_class=1):\n",
    "    fpr, tpr, thr = roc_curve(true_labels, predicted_labels, pos_class=pos_class)\n",
    "    area = -trapz(tpr, x=fpr)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52681072428971598"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(target, preds, pos_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Under the Curve (AUC)\n",
    "\n",
    "The less false positives and missed detections the higher the curve will be to the top left corner. This provides us with another simple metric to judge things on which is the area under the curve. The bigger the curve the better the classification performance. \n",
    "\n",
    "AUC is widely used choice for evaluating and comparing models, although in most cases it's important to inspect the full ROC curve in order to understand the performance trade-offs. \n",
    "\n",
    "#### Multiclass classifications\n",
    "\n",
    "The handwriting digits example is one of the most prolific ML cases. The ideas is to scan the handwritten digits and divide them into images with one letter in each. \n",
    "\n",
    "Using a random forest algo to build a classifier from the training set and generate the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "d = pandas.read_csv('data/mnist_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d[:int(0.8*len(d))]\n",
    "d_test = d[int(0.8*len(d)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the the forest algo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(d_train.drop('label', axis=1), d_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "preds = rf.predict(d_test.drop('label', axis=1))\n",
    "cm = confusion_matrix(d_test['label'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD3CAYAAAAwh5neAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1944f2d36d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matshow(cm, cmap=\"Greys\")\n",
    "colorbar()\n",
    "savefig('figures/multiclass_confusion_matrix.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix above you can see the greatest confusion occurs between digits 4 and 9, 3 and 5, 7 and 9, 2 and 6. This makes sense given the shapes of these and how they can be written by hand. \n",
    "\n",
    "For multiclass ROC's you assert that the positive class and that all other classes for that is negative for each class. And so for a 10 digit classifier you would have 10 roc curves (and 10x10 technically).\n",
    "\n",
    "#### Evaluation of regression models\n",
    "\n",
    "Classification models have a 'correct' prediction where regressions work on a numerical scale. A numeric prediction is in general unlikely to be exactly right, but it can be close to or fra from the correct value. So most evaluations focus on numerical distance from the correct value. \n",
    "\n",
    "This degree of uncertainty is known as the error. \n",
    "\n",
    "##### Roote-mean-square error (RMSE) and R^2\n",
    "\n",
    "This looks at the difference from each of the predicted values to the known values, and calculates the mean in a way that's immune to the fact that predicted values can be both higher and lower than the actual values. \n",
    "\n",
    "RMSE provides the same units as the values themselves but this also means that you can't easilly compare across datasets. If the predicted or actual values are larger numbers the RMSE will be correspondingly higher. This won't be a problem when comparing models in the same project it can challenge the understanding of the overall model performance and comparing it to othermodels in general. \n",
    "\n",
    "to help overcome this it can be worthwhile to compute R-squared. This is a relative response in the 0 to 1 range. If the model can predict the data better the R^2 value is closer to 1. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE\n",
    "def rmse(true_values, predicted_values):\n",
    "    n = len(true_values)\n",
    "    residuals = 0\n",
    "    for i in range(n):\n",
    "        residuals += (true_values[i] - predicted_values[i]) **2.\n",
    "    return np.sqrt(residuals/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38977403076025041"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(rand(10), rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#r^2\n",
    "def r2(true_values, predicted_values):\n",
    "    n=len(true_values)\n",
    "    mean = np.mean(true_values)\n",
    "    residuals = 0\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        residuals += (true_values[i] - predicted_values[i])**2.\n",
    "        total += (true_values[i] - mean) **2.\n",
    "    return 1.0 - residuals/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911028599294005"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(arange(10)+rand(), arange(10)+rand(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameter tuning\n",
    "\n",
    "each ML algo containts different set of tuning parameters that control how the algo uses training data to build a model. As the algos become more sophisticated, typically the tuning parameters become more numerous and esoteric. \n",
    "\n",
    "Logist Regression: none\n",
    "k-nearest neighbors: number of nearest neighbors to average\n",
    "decision trees:\n",
    "1. splitting criterion\n",
    "2. max depth of tree\n",
    "3. minimum samples needed to make a split\n",
    "Kernal SVM:\n",
    "1. kernal type\n",
    "2. kernel coefficient\n",
    "3. penalty parameter\n",
    "Random forest:\n",
    "1. number of trees\n",
    "2. number of features to split in each node\n",
    "3. splitting criterion\n",
    "4. minimum samples needed to make a split\n",
    "Boosting:\n",
    "1. number of trees\n",
    "2. number of features to split in each node\n",
    "3. learning rate\n",
    "4. max depth of tree\n",
    "5. splittin gcriterion\n",
    "6. minimum samples needed to make a split\n",
    "\n",
    "#### Grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pandas.read_csv('data/titanic.csv')\n",
    "\n",
    "#target\n",
    "y = d[\"Survived\"]\n",
    "\n",
    "# Features\n",
    "X = d.drop([\"Survived\", \"PassengerId\", \"Cabin\",\"Ticket\",\"Name\", \"Fare\"], axis=1)\n",
    "X['Sex'] = map(lambda x: 1 if x==\"male\" else 0, X['Sex'])\n",
    "X['Embarked-Q'] = map(lambda x: 1 if x==\"Q\" else 0, X['Embarked'])\n",
    "X['Embarked-C'] = map(lambda x: 1 if x==\"C\" else 0, X['Embarked'])\n",
    "X['Embarked-S'] = map(lambda x: 1 if x==\"S\" else 0, X['Embarked'])\n",
    "X = X.drop([\"Embarked\", \"Sex\"], axis=1)\n",
    "X = X.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-6dc729599a18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# build a model on the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgam_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcost_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# generate and store model predictions on the testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'map'"
     ]
    }
   ],
   "source": [
    "# grid of (gamma, C) values to try \n",
    "gam_vec, cost_vec = np.meshgrid(np.linspace(0.01, 10, 11),\n",
    "                     np.linspace(0.01, 10, 11))\n",
    "\n",
    "AUC_all = [] # initialize empty array to store AUC results\n",
    "\n",
    "# set up cross-validation folds\n",
    "N = len(y)\n",
    "K = 10 # number of cross-validation folds\n",
    "folds = np.random.randint(0, K, size=N)\n",
    "\n",
    "# search over every value of the grid\n",
    "for param_ind in np.arange(len(gam_vec.ravel())):\n",
    "\n",
    "    # initialize cross-validation predictions\n",
    "    y_cv_pred = np.empty(N)\n",
    "\n",
    "    # loop through the cross-validation folds\n",
    "    for ii in np.arange(K):\n",
    "        # break your data into training and testing subsets\n",
    "        X_train = X.iloc[folds != ii,:]\n",
    "        y_train = y.iloc[folds != ii]\n",
    "        X_test = X.iloc[folds == ii,:]\n",
    "\n",
    "        # build a model on the training set\n",
    "        model = SVC(gamma=gam_vec.ravel()[param_ind], C=cost_vec.ravel()[param_ind])\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # generate and store model predictions on the testing set\n",
    "        y_cv_pred[folds == ii] = model.predict(X_test)\n",
    "\n",
    "    # evaluate the AUC of the predictions\n",
    "    AUC_all.append(roc_auc_score(y, y_cv_pred))\n",
    "\n",
    "indmax = np.argmax(AUC_all)\n",
    "print( \"Maximum = %.3f\" %(np.max(AUC_all)) )\n",
    "print( \"Tuning Parameters: (gamma = %.2f, C = %.2f)\" % (gam_vec.ravel()[indmax], cost_vec.ravel()[indmax]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AUC_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-72c7fdac2c71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAUC_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUC_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgam_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcontourf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgam_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"kernel coefficient, gamma\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"penalty parameter, C\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AUC_all' is not defined"
     ]
    }
   ],
   "source": [
    "AUC_grid = np.array(AUC_all).reshape(gam_vec.shape)\n",
    "\n",
    "contourf(gam_vec, cost_vec, AUC_grid, 20, cmap='Greys')\n",
    "xlabel(\"kernel coefficient, gamma\")\n",
    "ylabel(\"penalty parameter, C\")\n",
    "colorbar()\n",
    "savefig(\"figures/figure-4.25.eps\", format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
